{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BuiThanhDam02/ML2023/blob/main/Lab_6_20130217_BuiThanhDam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab is to deal with classification task using **Random Forests** and **Na√Øve Bayes** algorithms with/without **Feature Selection**. \n",
        "\n",
        "*   **Deadline: 23:59, 25/03/2023**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "H4nJmxp9zGX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "DoVWQ8AEyc-C"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from prettytable import  PrettyTable\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.feature_selection import SelectKBest, chi2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1. \n",
        "Task 1. Compare the performance of selected classification algorithms including **Random forest**, **NaiveBayes**, and **SVM** with **mnist** dataset based on **accuracy, precision, recall, f1** measures according to **without using selection feature** and **using selection feature**.\n",
        "\n"
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "mnist = datasets.load_digits()\n",
        "Xtrain = mnist['data']\n",
        "ytrain = mnist['target']\n",
        "\n",
        "svm = svm.SVC(kernel='linear') # Linear Kernel\n",
        "\n",
        "svm.fit(Xtrain, ytrain)\n",
        "x_trainSVM, x_testSVM, y_trainSVM, y_testSVM = train_test_split(Xtrain,ytrain, test_size = 0.3, random_state = 0)\n",
        "\n",
        "y_predSVM = svm.predict(x_testSVM)\n",
        "\n",
        "accSvm =  accuracy_score(y_testSVM, y_predSVM)\n",
        "preSvm= metrics.precision_score(y_testSVM, y_predSVM,average='macro')\n",
        "\n",
        "recallSvm= metrics.recall_score(y_testSVM, y_predSVM,average='macro')\n",
        "f1Svm = metrics.f1_score(y_testSVM, y_predSVM,average='macro') "
      ],
      "metadata": {
        "id": "sOsg77IBzEyo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Create a Random Forest Classifier\n",
        "rfc=RandomForestClassifier(n_estimators=100)\n",
        "#Train the model using the training sets\n",
        "rfc.fit(Xtrain,ytrain)\n",
        "x_trainRFC, x_testRFC, y_trainRFC, y_testRFC = train_test_split(Xtrain,ytrain, test_size = 0.3, random_state = 0)\n",
        "\n",
        "y_predRFC = rfc.predict(x_testRFC)\n",
        "\n",
        "accRFC =  accuracy_score(y_testRFC, y_predRFC)\n",
        "preRFC= metrics.precision_score(y_testRFC, y_predRFC,average='macro')\n",
        "\n",
        "recallRFC= metrics.recall_score(y_testRFC, y_predRFC,average='macro')\n",
        "f1RFC = metrics.f1_score(y_testRFC, y_predRFC,average='macro') "
      ],
      "metadata": {
        "id": "NfiJeB-YzYo-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GaussianNB\n",
        "\n",
        "nb = GaussianNB()\n",
        "nb.fit(Xtrain, ytrain)\n",
        "\n",
        "x_trainNB, x_testNB, y_trainNB, y_testNB = train_test_split(Xtrain,ytrain, test_size = 0.3, random_state = 0)\n",
        "\n",
        "y_predNB = nb.predict(x_testNB)\n",
        "\n",
        "accNB =  accuracy_score(y_testNB, y_predNB)\n",
        "preNB= metrics.precision_score(y_testNB, y_predNB,average='macro')\n",
        "\n",
        "recallNB= metrics.recall_score(y_testNB, y_predNB,average='macro')\n",
        "f1NB = metrics.f1_score(y_testNB, y_predNB,average='macro') "
      ],
      "metadata": {
        "id": "0qQHSwqWzaS8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#svm using selection feature\n",
        "Xtrain_new = SelectKBest(chi2, k=20).fit_transform(Xtrain, ytrain)\n",
        "\n",
        "svm.fit(Xtrain_new, ytrain)\n",
        "x_trainSVMs, x_testSVMs, y_trainSVMs, y_testSVMs = train_test_split(Xtrain_new,ytrain, test_size = 0.3, random_state = 0)\n",
        "\n",
        "y_predSVMs = svm.predict(x_testSVMs)\n",
        "\n",
        "accSvms =  accuracy_score(y_testSVMs, y_predSVMs)\n",
        "preSvms= metrics.precision_score(y_testSVMs, y_predSVMs,average='macro')\n",
        "\n",
        "recallSvms= metrics.recall_score(y_testSVMs, y_predSVMs,average='macro')\n",
        "f1Svms = metrics.f1_score(y_testSVMs, y_predSVMs,average='macro') \n"
      ],
      "metadata": {
        "id": "bYsUDe7D_SAv"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rfc using selection feature\n",
        "rfc.fit(Xtrain_new,ytrain)\n",
        "x_trainRFCs, x_testRFCs, y_trainRFCs, y_testRFCs = train_test_split(Xtrain_new,ytrain, test_size = 0.3, random_state = 0)\n",
        "\n",
        "y_predRFCs = rfc.predict(x_testRFCs)\n",
        "\n",
        "accRFCs =  accuracy_score(y_testRFCs, y_predRFCs)\n",
        "preRFCs= metrics.precision_score(y_testRFCs, y_predRFCs,average='macro')\n",
        "\n",
        "recallRFCs= metrics.recall_score(y_testRFCs, y_predRFCs,average='macro')\n",
        "f1RFCs = metrics.f1_score(y_testRFCs, y_predRFCs,average='macro') \n"
      ],
      "metadata": {
        "id": "-NJT8f1SA3Rw"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#nb using selection feature\n",
        "\n",
        "nb.fit(Xtrain_new, ytrain)\n",
        "\n",
        "x_trainNBs, x_testNBs, y_trainNBs, y_testNBs = train_test_split(Xtrain_new,ytrain, test_size = 0.3, random_state = 0)\n",
        "\n",
        "y_predNBs = nb.predict(x_testNBs)\n",
        "\n",
        "accNBs =  accuracy_score(y_testNBs, y_predNBs)\n",
        "preNBs= metrics.precision_score(y_testNBs, y_predNBs,average='macro')\n",
        "\n",
        "recallNBs= metrics.recall_score(y_testNBs, y_predNBs,average='macro')\n",
        "f1NBs = metrics.f1_score(y_testNBs, y_predNBs,average='macro') \n"
      ],
      "metadata": {
        "id": "rIvtHZC9BVXZ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = PrettyTable(['Name Metric measure','SVM','Random Forest',\"Naive Bayes (Gaussian)\"])\n",
        "t.add_row(['Accuracy',accSvm,accRFC,accNB])\n",
        "t.add_row(['Precision Score',preSvm,preRFC,preNB])\n",
        "t.add_row(['Recall Score',recallSvm,recallRFC,recallNB])\n",
        "t.add_row(['F1',f1Svm,f1RFC,f1NB])\n",
        "print('Without using selection features')\n",
        "print(t)\n",
        "\n",
        "t2 = PrettyTable(['Name Metric measure','SVM','Random Forest',\"Naive Bayes (Gaussian)\"])\n",
        "t2.add_row(['Accuracy',accSvms,accRFCs,accNBs])\n",
        "t2.add_row(['Precision Score',preSvms,preRFCs,preNBs])\n",
        "t2.add_row(['Recall Score',recallSvms,recallRFCs,recallNBs])\n",
        "t2.add_row(['F1',f1Svms,f1RFCs,f1NBs])\n",
        "print('Using selection features')\n",
        "print(t2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4m7il6sBmGB",
        "outputId": "b0e7d989-ad6f-41fc-aaed-c3408c3f0600"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without using selection features\n",
            "+---------------------+-----+---------------+------------------------+\n",
            "| Name Metric measure | SVM | Random Forest | Naive Bayes (Gaussian) |\n",
            "+---------------------+-----+---------------+------------------------+\n",
            "|       Accuracy      | 1.0 |      1.0      |   0.8425925925925926   |\n",
            "|   Precision Score   | 1.0 |      1.0      |   0.8754996278813421   |\n",
            "|     Recall Score    | 1.0 |      1.0      |   0.8432015187160523   |\n",
            "|          F1         | 1.0 |      1.0      |   0.8469725015266443   |\n",
            "+---------------------+-----+---------------+------------------------+\n",
            "Using selection features\n",
            "+---------------------+--------------------+---------------+------------------------+\n",
            "| Name Metric measure |        SVM         | Random Forest | Naive Bayes (Gaussian) |\n",
            "+---------------------+--------------------+---------------+------------------------+\n",
            "|       Accuracy      | 0.9944444444444445 |      1.0      |   0.7851851851851852   |\n",
            "|   Precision Score   | 0.994745918356451  |      1.0      |   0.832840053703066    |\n",
            "|     Recall Score    | 0.9945419103313838 |      1.0      |   0.7909261566099561   |\n",
            "|          F1         | 0.9946288675872493 |      1.0      |   0.7850502437203137   |\n",
            "+---------------------+--------------------+---------------+------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2. \n",
        "For given bank dataset (bank.csv) having the following attributes :\n",
        "1.\t**age** (numeric)\n",
        "2.\t**job** : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
        "3.\t**marital** : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
        "4.\t**education** (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
        "5.\t**default**: has credit in default? (categorical: 'no','yes','unknown')\n",
        "6.\t**housing**: has housing loan? (categorical: 'no','yes','unknown')\n",
        "7.\t**loan**: has personal loan? (categorical: 'no','yes','unknown')\n",
        "8.\t**contact**: contact communication type (categorical: 'cellular','telephone')\n",
        "9.\t**month**: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
        "10.\t**day_of_week**: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
        "11.\t**duration**: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
        "12.\t**campaign**: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
        "13.\t**pdays**: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
        "14.\t**previous**: number of contacts performed before this campaign and for this client (numeric)\n",
        "15.\t**poutcome**: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
        "Output variable (desired target):\n",
        "16.\t**y**. has the client subscribed a term deposit? (binary: 'yes','no')\n",
        "\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/MyDrive/ColabNotebooks'\n",
        "dataset=pd.read_csv(\"bank.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfDHFToY4ePI",
        "outputId": "b894d84b-5979-4251-bb58-1538f4756900"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/ColabNotebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.1. Apply StandardScaler() function to columns that contains numerical data ('age', 'balance', 'day', 'campaign', 'pdays', 'previous')"
      ],
      "metadata": {
        "id": "q89LEvT7dqaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "\n",
        "scaler = StandardScaler();\n",
        "dataset[['age', 'balance', 'day', 'campaign', 'pdays', 'previous']] = scaler.fit_transform(dataset[['age', 'balance', 'day', 'campaign', 'pdays', 'previous']])\n",
        "print(dataset[['age', 'balance', 'day', 'campaign', 'pdays', 'previous']])\n"
      ],
      "metadata": {
        "id": "8vx3mfIidu4P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ff086a9-b022-45a0-95a6-cefba6786c99"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            age   balance       day  campaign     pdays  previous\n",
            "0      1.491505  0.252525 -1.265746 -0.554168 -0.481184 -0.363260\n",
            "1      1.239676 -0.459974 -1.265746 -0.554168 -0.481184 -0.363260\n",
            "2     -0.019470 -0.080160 -1.265746 -0.554168 -0.481184 -0.363260\n",
            "3      1.155733  0.293762 -1.265746 -0.554168 -0.481184 -0.363260\n",
            "4      1.071790 -0.416876 -1.265746 -0.186785 -0.481184 -0.363260\n",
            "...         ...       ...       ...       ...       ...       ...\n",
            "11157 -0.691015 -0.473616  0.515650 -0.554168 -0.481184 -0.363260\n",
            "11158 -0.187357 -0.246658  0.040612  0.547981 -0.481184 -0.363260\n",
            "11159 -0.774958 -0.464934  0.396891 -0.186785 -0.481184 -0.363260\n",
            "11160  0.148416 -0.473926 -0.909466 -0.186785  1.109571  1.818332\n",
            "11161 -0.607072 -0.473926 -0.790707 -0.554168 -0.481184 -0.363260\n",
            "\n",
            "[11162 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.2. Apply Encode Categorical Value (OneHotEncoder) to transfrom categorical data to numerical data ('job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome')"
      ],
      "metadata": {
        "id": "r7acR0TxdvY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "\n",
        "encoder=OneHotEncoder(sparse=False)\n",
        "dataset[['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']]= encoder.fit_transform(dataset[['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']])\n",
        "dataset[['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']]"
      ],
      "metadata": {
        "id": "egtgBmAtd0um",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "0342f3de-27ea-4de1-df08-5b668d75c735"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       job  marital  education  default  housing  loan  contact  month  \\\n",
              "0      1.0      1.0        1.0      1.0      1.0   1.0      1.0    1.0   \n",
              "1      1.0      1.0        1.0      1.0      1.0   1.0      1.0    1.0   \n",
              "2      1.0      1.0        1.0      1.0      1.0   1.0      1.0    1.0   \n",
              "3      1.0      1.0        1.0      1.0      1.0   1.0      1.0    1.0   \n",
              "4      1.0      1.0        1.0      1.0      1.0   1.0      1.0    1.0   \n",
              "...    ...      ...        ...      ...      ...   ...      ...    ...   \n",
              "11157  1.0      1.0        1.0      1.0      1.0   1.0      1.0    1.0   \n",
              "11158  1.0      1.0        1.0      1.0      1.0   1.0      1.0    1.0   \n",
              "11159  1.0      1.0        1.0      1.0      1.0   1.0      1.0    1.0   \n",
              "11160  1.0      1.0        1.0      1.0      1.0   1.0      1.0    1.0   \n",
              "11161  1.0      1.0        1.0      1.0      1.0   1.0      1.0    1.0   \n",
              "\n",
              "       poutcome  \n",
              "0           1.0  \n",
              "1           1.0  \n",
              "2           1.0  \n",
              "3           1.0  \n",
              "4           1.0  \n",
              "...         ...  \n",
              "11157       1.0  \n",
              "11158       1.0  \n",
              "11159       1.0  \n",
              "11160       1.0  \n",
              "11161       1.0  \n",
              "\n",
              "[11162 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-64d608b9-cf11-42c1-baaf-969dfb1a68ae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>month</th>\n",
              "      <th>poutcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11157</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11158</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11159</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11160</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11161</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11162 rows √ó 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64d608b9-cf11-42c1-baaf-969dfb1a68ae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-64d608b9-cf11-42c1-baaf-969dfb1a68ae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-64d608b9-cf11-42c1-baaf-969dfb1a68ae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.3. Apply **Decision tree, Random forest, kNN, Na√ØveBayes** to preproceed dataset in the previous steps. Then compare the obtained results using **accuracy, precision, recall, f1** measures."
      ],
      "metadata": {
        "id": "K2Si6d69d1nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code"
      ],
      "metadata": {
        "id": "Ouil-cf_d8jW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.4. Using selection feature to above dataset, then compare the classification results with those in Task 2.3. "
      ],
      "metadata": {
        "id": "SweVRB4meApP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code"
      ],
      "metadata": {
        "id": "seFBhqCSeC7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4. \n",
        "For a given dataset in the Lab #5 (**credit card dataset**), perform feature selection and thencompare the performance of selected classification algorithms (Decision Tree, kNN, Logistic Regression, SVM, Random Forest and NaiveBayes) based on accuracy, precision, recall, f1 measures.\n"
      ],
      "metadata": {
        "id": "Z5pp7_h-aP2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code"
      ],
      "metadata": {
        "id": "Rw_-8FIf2KxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}